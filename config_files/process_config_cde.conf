# Description: Logstash configuration script to recieve process data, parse and then push it to Kafka

input {
	file {
		path => "/home/4px/condition_data_de_edit_edit.csv"
		start_position => "beginning"
		sincedb_path => "/home/4px/condition_data_de.log"
	}
}


filter {
	csv {
		separator => ","
		skip_header => "true"
		columns => ["event_timestamp", "tag__id", "tag__name", "tag__desc", "tag__value", "tag__unit", "device_identifier"]
 	}
	mutate {
		remove_field => [ "@version", "message", "path", "host"]
	}
}


output {
	stdout {}
	kafka {
		acks => '1'
		codec => "json"
		topic_id => "3e67bd57-4a0d-4201-a9aa-a5055e550c466"
		bootstrap_servers => "34.135.68.182:9092"
		sasl_jaas_config => "org.apache.kafka.common.security.plain.PlainLoginModule required username='admin'  password='admin-secret';"
		sasl_mechanism => "PLAIN"
		security_protocol => "SASL_PLAINTEXT"
	}
}
